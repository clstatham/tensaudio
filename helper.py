import numpy as np
import torch
from torch.autograd import Function
from sklearn.preprocessing import normalize

import librosa
import soundfile

from global_constants import *

# LEAKY RELU UNIT
def lrelu(x):
    return torch.max(0.2*x,x)


# GENERATE DILATED LAYER FROM 1D SIGNAL
def signal_to_dilated(signal, dilation, n_channels):
    shape = tf.shape(signal)
    pad_elements = dilation - 1 - (shape[2] + dilation - 1) % dilation
    dilated = tf.pad(signal, [[0, 0], [0, 0], [0, pad_elements], [0, 0]])
    dilated = tf.reshape(dilated, [shape[0],-1,dilation,n_channels])
    return tf.transpose(dilated, perm=[0,2,1,3]), pad_elements


# COLLAPSE DILATED LAYER TO 1D SIGNAL
def dilated_to_signal(dilated, pad_elements, n_channels):
    shape = tf.shape(dilated)
    signal = tf.transpose(dilated, perm=[0,2,1,3])
    signal = tf.reshape(signal, [shape[0],1,-1,n_channels])
    return signal[:,:,:shape[1]*shape[2]-pad_elements,:]


# ADAPTIVE BATCH NORMALIZATION LAYER
def nm(x):
    w0=tf.Variable(1.0,name='w0')
    w1=tf.Variable(0.0,name='w1')
    return w0*x+w1*tf.keras.layers.BatchNormalization()(x)


# IDENTITY INITIALIZATION OF CONV LAYERS
def identity_initializer():
    def _initializer(shape, dtype=tf.float32, partition_info=None):
        array = np.zeros(shape, dtype=float)
        cx, cy = shape[0]//2, shape[1]//2
        for i in range(np.minimum(shape[2],shape[3])):
            array[cx, cy, i, i] = 1
        return tf.constant(array, dtype=dtype)
    return _initializer

def l1_loss_batch(target):
    return tf.reduce_mean(tf.abs(target),axis=[1,2,3])

# L1 LOSS FUNCTION
def l1_loss(target,current):
    return tf.reduce_mean(tf.abs(target-current))

def l1_loss_all(agg):
    return tf.reduce_mean(tf.abs(agg))

def l2_loss_all(agg):
    return tf.reduce_mean(tf.square(agg))

def l1_loss_batch(target):
    return tf.reduce_mean(tf.abs(target),axis=[1,2,3])

def l1_loss_batch(target):
    return tf.reduce_mean(tf.abs(target),axis=[1,2,3])

# L2 LOSS FUNCTION
def l2_loss(target,current):
    return torch.mean(torch.square(target-current))

def l2_loss_unit(target,current):
    target=tf.linalg.l2_normalize(target,axis=3)
    current = tf.linalg.l2_normalize(current,axis=3)
    return tf.reduce_mean(tf.square(target-current))

def frame(data, window_length, hop_length):
  """Convert array into a sequence of successive possibly overlapping frames.
  An n-dimensional array of shape (num_samples, ...) is converted into an
  (n+1)-D array of shape (num_frames, window_length, ...), where each frame
  starts hop_length points after the preceding one.
  This is accomplished using stride_tricks, so the original data is not
  copied.  However, there is no zero-padding, so any incomplete frames at the
  end are not included.
  Args:
    data: np.array of dimension N >= 1.
    window_length: Number of samples in each frame.
    hop_length: Advance (in samples) between each window.
  Returns:
    (N+1)-D np.array with as many rows as there are complete frames that can be
    extracted.
  """
  num_samples = data.shape[0]
  num_frames = 1 + int(np.floor((num_samples - window_length) / hop_length))
  shape = (num_frames, window_length) + data.shape[1:]
  strides = (data.strides[0] * hop_length,) + data.strides
  return np.lib.stride_tricks.as_strided(data, shape=shape, strides=strides)


def periodic_hann(window_length):
  """Calculate a "periodic" Hann window.
  The classic Hann window is defined as a raised cosine that starts and
  ends on zero, and where every value appears twice, except the middle
  point for an odd-length window.  Matlab calls this a "symmetric" window
  and np.hanning() returns it.  However, for Fourier analysis, this
  actually represents just over one cycle of a period N-1 cosine, and
  thus is not compactly expressed on a length-N Fourier basis.  Instead,
  it's better to use a raised cosine that ends just before the final
  zero value - i.e. a complete cycle of a period-N cosine.  Matlab
  calls this a "periodic" window. This routine calculates it.
  Args:
    window_length: The number of points in the returned window.
  Returns:
    A 1D np.array containing the periodic hann window.
  """
  return 0.5 - (0.5 * np.cos(2 * np.pi / window_length *
                            np.arange(window_length)))


def stft_magnitude(signal, fft_length,
                  hop_length=None,
                  window_length=None):
  """Calculate the short-time Fourier transform magnitude.
  Args:
    signal: 1D np.array of the input time-domain signal.
    fft_length: Size of the FFT to apply.
    hop_length: Advance (in samples) between each frame passed to FFT.
    window_length: Length of each block of samples to pass to FFT.
  Returns:
    2D np.array where each row contains the magnitudes of the fft_length/2+1
    unique values of the FFT for the corresponding frame of input samples.
  """
  frames = frame(signal, window_length, hop_length)
  # Apply frame window to each frame. We use a periodic Hann (cosine of period
  # window_length) instead of the symmetric Hann of np.hanning (period
  # window_length-1).
  window = periodic_hann(window_length)
  windowed_frames = frames * window
  return np.abs(np.fft.rfft(windowed_frames, int(fft_length)))


# Mel spectrum constants and functions.
_MEL_BREAK_FREQUENCY_HERTZ = 700.0
_MEL_HIGH_FREQUENCY_Q = 1127.0


def hertz_to_mel(frequencies_hertz):
  """Convert frequencies to mel scale using HTK formula.
  Args:
    frequencies_hertz: Scalar or np.array of frequencies in hertz.
  Returns:
    Object of same size as frequencies_hertz containing corresponding values
    on the mel scale.
  """
  return _MEL_HIGH_FREQUENCY_Q * np.log(
      1.0 + (frequencies_hertz / _MEL_BREAK_FREQUENCY_HERTZ))


def spectrogram_to_mel_matrix(num_mel_bins=64,
                              num_spectrogram_bins=129,
                              audio_sample_rate=8000,
                              lower_edge_hertz=125.0,
                              upper_edge_hertz=3800.0):
  """Return a matrix that can post-multiply spectrogram rows to make mel.
  Returns a np.array matrix A that can be used to post-multiply a matrix S of
  spectrogram values (STFT magnitudes) arranged as frames x bins to generate a
  "mel spectrogram" M of frames x num_mel_bins.  M = S A.
  The classic HTK algorithm exploits the complementarity of adjacent mel bands
  to multiply each FFT bin by only one mel weight, then add it, with positive
  and negative signs, to the two adjacent mel bands to which that bin
  contributes.  Here, by expressing this operation as a matrix multiply, we go
  from num_fft multiplies per frame (plus around 2*num_fft adds) to around
  num_fft^2 multiplies and adds.  However, because these are all presumably
  accomplished in a single call to np.dot(), it's not clear which approach is
  faster in Python.  The matrix multiplication has the attraction of being more
  general and flexible, and much easier to read.
  Args:
    num_mel_bins: How many bands in the resulting mel spectrum.  This is
      the number of columns in the output matrix.
    num_spectrogram_bins: How many bins there are in the source spectrogram
      data, which is understood to be fft_size/2 + 1, i.e. the spectrogram
      only contains the nonredundant FFT bins.
    audio_sample_rate: Samples per second of the audio at the input to the
      spectrogram. We need this to figure out the actual frequencies for
      each spectrogram bin, which dictates how they are mapped into mel.
    lower_edge_hertz: Lower bound on the frequencies to be included in the mel
      spectrum.  This corresponds to the lower edge of the lowest triangular
      band.
    upper_edge_hertz: The desired top edge of the highest frequency band.
  Returns:
    An np.array with shape (num_spectrogram_bins, num_mel_bins).
  Raises:
    ValueError: if frequency edges are incorrectly ordered or out of range.
  """
  nyquist_hertz = audio_sample_rate / 2.
  if lower_edge_hertz < 0.0:
    raise ValueError("lower_edge_hertz %.1f must be >= 0" % lower_edge_hertz)
  if lower_edge_hertz >= upper_edge_hertz:
    raise ValueError("lower_edge_hertz %.1f >= upper_edge_hertz %.1f" %
                    (lower_edge_hertz, upper_edge_hertz))
  if upper_edge_hertz > nyquist_hertz:
    raise ValueError("upper_edge_hertz %.1f is greater than Nyquist %.1f" %
                    (upper_edge_hertz, nyquist_hertz))
  spectrogram_bins_hertz = np.linspace(0.0, nyquist_hertz, num_spectrogram_bins)
  spectrogram_bins_mel = hertz_to_mel(spectrogram_bins_hertz)
  # The i'th mel band (starting from i=1) has center frequency
  # band_edges_mel[i], lower edge band_edges_mel[i-1], and higher edge
  # band_edges_mel[i+1].  Thus, we need num_mel_bins + 2 values in
  # the band_edges_mel arrays.
  band_edges_mel = np.linspace(hertz_to_mel(lower_edge_hertz),
                              hertz_to_mel(upper_edge_hertz), num_mel_bins + 2)
  # Matrix to post-multiply feature arrays whose rows are num_spectrogram_bins
  # of spectrogram values.
  mel_weights_matrix = np.empty((num_spectrogram_bins, num_mel_bins))
  for i in range(num_mel_bins):
    lower_edge_mel, center_mel, upper_edge_mel = band_edges_mel[i:i + 3]
    # Calculate lower and upper slopes for every spectrogram bin.
    # Line segments are linear in the *mel* domain, not hertz.
    lower_slope = ((spectrogram_bins_mel - lower_edge_mel) /
                  (center_mel - lower_edge_mel))
    upper_slope = ((upper_edge_mel - spectrogram_bins_mel) /
                  (upper_edge_mel - center_mel))
    # .. then intersect them with each other and zero.
    mel_weights_matrix[:, i] = np.maximum(0.0, np.minimum(lower_slope,
                                                          upper_slope))
  # HTK excludes the spectrogram DC bin; make sure it always gets a zero
  # coefficient.
  mel_weights_matrix[0, :] = 0.0
  return mel_weights_matrix


def log_mel_spectrogram(data,
                        audio_sample_rate=44100,
                        log_offset=0.01,
                        window_length_secs=0.025,
                        hop_length_secs=0.010,
                        **kwargs):
  """Convert waveform to a log magnitude mel-frequency spectrogram.
  Args:
    data: 1D np.array of waveform data.
    audio_sample_rate: The sampling rate of data.
    log_offset: Add this to values when taking log to avoid -Infs.
    window_length_secs: Duration of each window to analyze.
    hop_length_secs: Advance between successive analysis windows.
    **kwargs: Additional arguments to pass to spectrogram_to_mel_matrix.
  Returns:
    2D np.array of (num_frames, num_mel_bins) consisting of log mel filterbank
    magnitudes for successive frames.
  """
  window_length_samples = int(round(audio_sample_rate * window_length_secs))
  hop_length_samples = int(round(audio_sample_rate * hop_length_secs))
  fft_length = 2 ** int(np.ceil(np.log(window_length_samples) / np.log(2.0)))
  spectrogram = stft_magnitude(
      data,
      fft_length=fft_length,
      hop_length=hop_length_samples,
      window_length=window_length_samples)
  mel_spectrogram = np.dot(spectrogram, spectrogram_to_mel_matrix(
      num_spectrogram_bins=spectrogram.shape[1],
      audio_sample_rate=audio_sample_rate, **kwargs))
  return np.log(mel_spectrogram + log_offset)


def voc_ap(rec, prec, use_07_metric=True):
    """ ap = voc_ap(rec, prec, [use_07_metric])
    Compute VOC AP given precision and recall.
    If use_07_metric is true, uses the
    VOC 07 11 point method (default:False).
    """
    if use_07_metric:
        # 11 point metric
        ap = 0.
        for t in np.arange(0., 1.1, 0.1):
            if np.sum(rec >= t) == 0:
                p = 0
            else:
                p = np.max(prec[rec >= t])
            ap = ap + p / 11.
    else:
        
        # correct AP calculation
        # first append sentinel values at the end
        mrec = np.concatenate(([0.], rec, [1.]))
        mpre = np.concatenate(([0.], prec, [0.]))
        #cprint('abc')
        # compute the precision envelope
        for i in range(mpre.size - 1, 0, -1):
            mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])

        # to calculate area under PR curve, look for points
        # where X axis (recall) changes value
        i = np.where(mrec[1:] != mrec[:-1])[0]

        # and sum (\Delta recall) * prec
        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])
    return ap

def find_shape_from(actual, exp_batches, exp_channels, exp_timesteps):
  # order is important here for dumb reasons
  if exp_timesteps is None:
    exp_timesteps = np.max((1, (actual / (exp_channels * exp_batches))))
  if exp_batches is None:
    exp_batches = np.max((1, (actual / (exp_channels * exp_timesteps))))
  if exp_channels is None:
    exp_channels = np.max((1, (actual / (exp_batches * exp_timesteps))))
  target = int(exp_batches)*int(exp_channels)*int(exp_timesteps)
  if target != actual:
    # try again in case one was None
    t = np.max((1, (actual / (exp_channels * exp_batches))))
    b = np.max((1, (actual / (exp_channels * exp_timesteps))))
    c = np.max((1, (actual / (exp_batches * exp_timesteps))))
    target = int(t)*int(b)*int(c)
    if target == actual:
      return (int(t), int(b), int(c))
    raise Exception(str(target)+" != "+str(actual))
  return (int(exp_batches), int(exp_channels), int(exp_timesteps))

def ensure_size(t, size, channels=1):
  if channels == 1:
    t = t.flatten()
    delta = t.shape[0] - size
    if delta < 0:
      if type(t) == torch.Tensor:
        t = torch.cat((t, torch.zeros(-delta).cuda()))
      else:
        t = np.concatenate((t, np.zeros(-delta)))
    elif delta > 0:
      t = t[:-delta]
  else:
    delta = t.shape[1]*channels - size
    if delta < 0:
      if type(t) == torch.Tensor:
        t = torch.tensor([torch.cat(t[i], torch.zeros(t[i].shape[0])) for i in range(channels)]).cuda()
      else:
        t = [np.concatenate(t[i], np.zeros(len(t[i]))) for i in range(channels)]
    elif delta > 0:
      t = t[:][:-delta]
  return t, delta

class DataBatchPrep(Function):
  @staticmethod
  def forward(ctx, inp, exp_batches, exp_channels, exp_timesteps):
    ctx.set_materialize_grads(False)
    ctx.exp_batches = exp_batches
    ctx.exp_channels = exp_channels
    ctx.exp_timesteps = exp_timesteps
    ctx.save_for_backward(torch.empty_like(inp))
    ctx.mark_dirty(inp)
    inp_ = inp.detach()
    return inp.new(prep_data_for_batch_operation(inp_, exp_batches, exp_channels, exp_timesteps, greedy=False, return_shape=False).to(inp.device)), inp
  def backward(ctx, grad_output, dummy):
    if grad_output is None:
      return None, None, None, None
    orig_shape = ctx.saved_tensors[0]
    return torch.reshape(grad_output, orig_shape.shape), None, None, None

def prep_data_for_batch_operation(t, exp_batches, exp_channels, exp_timesteps, greedy=False, return_shape=False):
  t = torch.flatten(t)
  actual = t.shape[0]
  b, c, s = None, None, None
  delta = 0
  try:
    b, c, s = find_shape_from(actual, exp_batches, exp_channels, exp_timesteps)
  except Exception as e:
    if greedy:
      # zero pad the result until it's valid
      while b is None or c is None or s is None:
        delta += 1
        try:
          b, c, s = find_shape_from(actual+delta, exp_batches, exp_channels, exp_timesteps)
        except:
          pass
      t = torch.cat((t, torch.zeros(delta).cuda()))
    else:
      raise e
  if greedy:
    if return_shape:
      return torch.reshape(torch.as_tensor(t).cuda(), (b, c, s)), delta, (b,c,s)
    else:
      return torch.reshape(torch.as_tensor(t).cuda(), (b, c, s)), delta
  else:
    if return_shape:
      return torch.reshape(torch.as_tensor(t).cuda(), (b, c, s)), (b,c,s)
    else:
      return torch.reshape(torch.as_tensor(t).cuda(), (b, c, s))
  #return tf.reshape(t, (N_BATCHES, 2, 1))
def normalize_audio(tensor):
  # Subtract the mean, and scale to the interval [-1,1]
  tensor_minusmean = tensor - tensor.mean()
  return tensor_minusmean/tensor_minusmean.abs().max()
def write_normalized_audio_to_disk(sig, fn):
  sig_numpy = normalize_audio(sig.clone().detach().cpu()).numpy()
  scaled = np.int16(sig_numpy * 32767)
  soundfile.write(fn, scaled, SAMPLE_RATE, SUBTYPE)

class FFTWithGradients(Function):
    @staticmethod
    def forward(ctx, p):
        p_ = p.detach().cpu().numpy()
        result = np.fft.fft(p_.astype('float32'))
        real = np.real(result)
        ctx.save_for_backward(real)
        imag = np.imag(result)
        ctx.save_for_backward(imag)
        mag = np.sqrt(real**2 + imag**2)
        phas = np.arctan2(real, imag)
        return p.new((mag, phas))

    @staticmethod
    def backward(ctx, grad_output):
        if grad_output is None:
          return None, None
        numpy_go = grad_output.cpu().numpy()
        #print(numpy_go.shape)
        data = []
        for i in range(len(ctx.real)):
          d = []
          for j in range(len(ctx.real[i])):
            d.append(np.complex(ctx.real[i][j], ctx.imag[i][j]))
          data.append(d)
        data = np.array(data)
        orig_size = data.size//2
        #print(orig_size)
        result = np.fft.ifft(data)
        #print(result.shape)
        result, _ = ensure_size(result, TOTAL_SAMPLES_OUT, channels=1)
        return grad_output.new(result)

class InverseFFTWithGradients(Function):
    @staticmethod
    def forward(ctx, p):
        p_ = p.detach().cpu().numpy()
        result = np.fft.ifft(p_)
        return p.new((np.real(result), np.imag(result)))

    @staticmethod
    def backward(ctx, grad_output):
        if grad_output is None:
          return None, None
        numpy_go = grad_output.cpu().numpy()
        result = np.fft.fft(numpy_go)
        return grad_output.new((np.real(result), np.imag(result)))
